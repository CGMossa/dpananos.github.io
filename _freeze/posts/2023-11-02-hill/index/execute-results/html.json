{
  "hash": "30c9a76bf3480fc8aad29d55bd23da70",
  "result": {
    "markdown": "---\ntitle: Optimal Designs for Certain Functions\ndate: \"2023-11--2\"\ncode-fold: true\necho: true\nfig-cap-location: top\ncategories: []\nnumber-sections: false\ndraft: false\n---\n\n\nThis post serves as breadcrumbs for some thoughts and research I've been doing.\n\n---\n\nI'm chewing on a problem which may or may not be useful.  Say you need to estimate the parameter $k$ in the following function\n\n$$ f(x) = \\dfrac{k x}{k+x} \\>, \\quad 0 \\lt x \\>.$$\n\nYou are constrained by ...something..., and so you can't sample as much as you like; you can only make a few samples.  Where should those samples be [^1]? \n\nThe question \"where should you sample?\" suggests that not all samples are equal.  How can samples be unequal?  How can we tell that one sample is better than another? It might be easier to first start with a simpler function, one we all know well.\n\n## A Simple Function\n\nRather than this non-linear function above, what if instead we studied \n\n$$ g(x) = \\beta_0 + \\beta_1 x \\>? $$\n\nTo repeat, our goal is to estimate the parameters of this model and to do so with limited data. We can estimate the parameters of this model using OLS, which we know well.  So now let's ask ourselves \"how can one sample be better than another\"?  If I gave you a sample of $n$ observations and all the $x$ were the same then that would be a bad sample for the goal of estimating the parameters.  That's because in order to learn the parameters, the $x$ need to have non-zero sample variance.  If the $x$ have 0 sample variance, then the estimate for $\\beta_1$ doesn't exist (see denominator of the estimate below)\n\n$$ \\hat{\\beta}_1 = \\dfrac{\\sum_{i=1}^n (x_i-\\bar{x}) (y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}  \\>.$$\n\nThis is true of most models.  If your sample doesn't vary, you can't learn much.  So maybe a sample being \"good\" has something to do with variability.  Obviously no variability in the sample is bad (since we can't get an estimate), but can too much variability be bad too?\n\nFor some functions, yes. If you sample in a region that doesn't have much variation in the outcome, you don't learn much either.  Think of a logistic regression.  If you sample too much where things are very likely to occur, you won't learn much either.  Clearly, there is some sort of balance when it comes to variability.  How can we choose how variable to make our sample?\n\nReturning back to $g(x)$ for a moment, we've established not all samples are equal.  Aside from pathological cases where there is no variability in the $x$ (and the estimate can not be obtained), the precision of the estimate is impacted by the sample.\n\n\n\n\n::: {.cell fig.asp='0.61'}\n\n```{.r .cell-code}\npar(mfrow = c(1, 2))\n\nset.seed(0)\nN <- 10\nx <- rnorm(N, 0.75, 0.1)\nxpred <- seq(-3, 3, length.out=100)\ny <- 2*x + 1 + rnorm(N, 0, 0.5)\nfit_1 <- lm(y~x)\npred <- predict(fit_1, newdata = list(x=xpred), interval = 'confidence')\npred_int <- pred[, 2:3]\n\nplot(x, y, xlim = c(-2, 2), ylim = c(-5, 5), main = 'Less Certain', pch=20)\npolygon(c(xpred, rev(xpred)), y=c(pred_int[,1], rev(pred_int[,2])), col=rgb(48/256, 61/256, 78/256, 0.5))\nabline(a=1, b=2)\nabline(reg=fit_1, lty=2)\n\n\nx <- rnorm(N, 0, 1)\ny <- 2*x + 1 + rnorm(N, 0, 0.5)\nxpred <- seq(-3, 3, length.out=100)\nfit_2 <- lm(y~x)\npred <- predict(fit_2, newdata = list(x=xpred), interval = 'confidence')\npred_int <- pred[, 2:3]\n\nplot(x, y, xlim = c(-2, 2), ylim = c(-5, 5), main = 'More Certain', pch=20)\npolygon(c(xpred, rev(xpred)), y=c(pred_int[,1], rev(pred_int[,2])), col=rgb(48/256, 61/256, 78/256, 0.5))\nabline(a=1, b=2)\nabline(reg=fit_1, lty=2)\n```\n\n::: {.cell-output-display}\n![Confidence interval for the conditional mean.  True function in dashed black, estimated in solid black.  On the left, the sample is very tightly centered around 0 and hence has smaller sampling variability.  On the right, the sample has larger sampling variabulity which increases the precision in the conditional expectation.](index_files/figure-html/figureOne-1.png){width=672}\n:::\n:::\n\n\n\nMaybe the one way to think about how one sample might be better than another is to think about what kind of precision is afforded by the sample.  For simple functions like $g(x)$, that is easy to operationalize.  Consider for a moment the covariance matrix for the coefficients in $g(x)$.  Using $SS_x = \\sum_i (x-\\bar{x})^2$, the matrix is\n\n$$ \\Sigma = \\hat{\\sigma}^2X'X =\\hat{\\sigma}^2\n\\begin{bmatrix} \n\\dfrac{\\sum x_i^2}{nSS_x} & -\\dfrac{\\bar{x}}{SS_x} \\\\\n-\\dfrac{\\bar{x}}{SS_x} & \\dfrac{1}{SS_x}\n\\end{bmatrix} \\>.$$\n\nTo make the estimate for $\\beta_1$ as precise as possible, we need to maximize $SS_x$.  In practice, this means taking the $x$ to be as far apart as possible.  To make the estimate of the intercept as precise as possible we need to make $SS_x$ as large as possible *while not making $\\sum x^2_i$ not too ig. How do we make both as precise as possible?\n\n\n## A Small Digression Into Linear Algebra\n\n\nOk, before we answer that we have to remember a couple things:\n\n* Matrices are linear transformations (rotations and scalings and such), and\n* The determinant of a matrix tells you how much a the area of a unit square is changed due to the stretching.\n\n::: {.cell fig.asp='0.61'}\n\n```{.r .cell-code}\ntt <- 2*pi*ppoints(5000)\nR <- cbind(cos(tt), sin(tt))\n\nS <- vcov(fit_1)\nA <- chol(S)\n\npar(mfrow = c(1, 2))\nplot(R, \n     type = 'l',\n     xlab = 'x',\n     ylab='y',\n     xlim = c(-2.25, 2.25),\n     ylim=c(-2.25, 2.25),\n     main='Natural')\nlines(2*R, lty='dashed')\n\n\nplot(R %*% A, \n     type = 'l',\n     xlab = 'x',\n     ylab='y',\n     xlim = c(-2.25, 2.25),\n     ylim=c(-2.25, 2.25),\n     main='Transformed')\nlines(2*R %*% A, \n      lty='dashed')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n[^1]: We're getting to D-optimal designs in pharmacodynamics or something like that, but let's pretend we don't know that.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}