{
  "hash": "ca82d6ce7fba95333eba4ae9bab7dada",
  "result": {
    "markdown": "---\ntitle: \"Bad Takes on R squared\"\ndate: \"2023-05-14\"\ncode-fold: true\necho: false\nfig-cap-location: top\ncategories: [Statistics]\nnumber-sections: false\ndraft: false\n---\n\n\nTo the best of twitter's ability, it seems the seemingly never ending bad takes on R squared as of late could be attributed to [this tweet](https://twitter.com/nntaleb/status/1658388770893250560) by Nassim Taleb.\n\nThe tweet is a quote tweet of another user showing a scatter plot with a regression line, seemingly conveying that more plutocracy is associated with more murders.  The quoted tweet concludes *\"Hmm .. maybe inequality really is structural violence\"*, which is what I anticipate caught Taleb's attention.\n\nBut I'm not so much interested in the cause as I am the consequences.  After that tweet, so many people came out and criticized the quoted tweet for...the regression's R squared?  Many claiming that the R squared was too low to support the author's conclusion that inequality is structural violence.\n\nThese people are right for the wrong reasons.  The author is not permitted to make such a conclusion on the basis of a simple regression alone, but the reason for that has nothing to do with the R squared.\n\nIn this post, I examine:\n\n* What R squared (a.k.a coefficient of determination) is\n* What it is and isn't good for, and\n* Try to identify exactly why people dig in their heels that a low R squared means the inference is not valid (or at least not reliable).\n\nI will focus almost exclusively on the coefficient of determination found in most OLS outputs, rather than say [generalized measures of R squared or pseudo R squared](https://en.wikipedia.org/wiki/Pseudo-R-squared) which have more to do with likelihood ratio statistics and are more useful in prediction problems.\n\n## The Coefficient of Determination is Proportional to The Ratio of Residual Variance to Marginal Variance\n\nThe coefficient of determination is\n\n$$ R^2 = 1 - \\dfrac{\\sum_j (y_j - \\hat{y}_j)^2}{\\sum_j (y_j - \\bar{y}_j)^2} \\>.$$\n\nDo a little algebra[^1] and\n\n[^1]: Worth mentioning here that dividing by $1/n$ ignores degrees of freedom spent in estimating $\\hat{y}$.  This probably results in a little bit of bias in the finite sample case, but let's pretend that we have enough data and few enough observations that this does not matter much.  The adjusted $R^2$ does this propery by accounting for the degrees of freedom.\n\n\n$$ \\begin{align}\n&= 1 - \\dfrac{\\frac{1}{n}}{\\frac{1}{n}}\\dfrac{\\sum_j (y_j - \\hat{y}_j)^2}{\\sum_j (y_j - \\bar{y}_j)^2} \\\\\n&= 1 - \\dfrac{\\hat{\\sigma}^2_{y\\mid x}}{\\hat{\\sigma}^2_y} \\\\\n\\end{align}$$\n\nyou see that $R^2$ is proportional to the ratio of residual variance $\\hat{\\sigma}^2_{y\\mid x}$ to sample marginal variance $\\hat{\\sigma}^2_y$.  That's it, that is all it measures; how much of the variance in the marginal distribution can be attributed to variation in the covariates.  This is also why the statistic is often interpreted as \"proportion of variance explained\".\n\n## The Coefficient of Determination Bears No Information on Causation or Reliability of Inference\n\nMany of the complaints about R squared being too low go something like \n\n>[\"...so bascially no connection that couldn't be explained by unnoticed/ignored confounders\"](https://twitter.com/PhDemetri/status/1658665814214553600)\n\nor \n\n>[\"R square is 18% how is it a good fit...But would you conclude the effect with such low R squared.\"](https://twitter.com/firstkaransingh/status/1657774655112097797)\n\nThere are many more, but these are just two worth mentioning.  What do these commenters mean here?\n\nIt would seem that confounding is suspected of the relationship.  I agree; simple OLS is basically an examination of correlation and we all know correlation is not definitely evidence of causation. But R squared does not tell us about the presence or absence of confounding.  In fact, *de facto* cases of causation can have low r squared.  Here is an example.\n\nSuppose you run a randomized control trial on a continuous in which the outcome has a standard deviation of 5 (variance of 25).  You're interested in a small effect size, but can power the experiment as much as you like.  Let's simulate this RCT to have 90% power.  A t-test is the way to analyze these data to assess differences in mean outcomes, and this can be done using OLS.  Given these assumptions, what do you think the expected R squared for the OLS would be?\n\nHow about less than 1%.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![R squared from 1,000 simulations of the aformentioned theoretical RCT.  Treeatment balance is exactly 50/50 in each simulation.  There is no other confounder, simply noise in the measurement process.  This is what drives the low R squared](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nAnd yet, we have causation due to our assumptions.  Clearly, large R squared has nothing to tell us about causation or the existence of an effect.  Not even in theory, let alone practice.  These comments just make no sense to me.\n\n## People Are Complex, Data is Noisy\n\nNow, this previous example just provides a counter example to comments that claim results with low R squared can be brushed aside due to confounding or unreliability. I've clearly outlined a case where causation exists, the effects are detected with high probability, and yet the R squared is basically 0.  You can't get much lower than that.\n\nIts a mostly mathematical type of response and I have to credit people who are able to communicate their thoughts more clearly to a non-mathematical audience than I can.  I especially like [this response](https://twitter.com/smartin2018/status/1658898763551997952) by Stephen Martin who comments on just how complex and enormous data generating processes in social science can be.  Or [this response](https://twitter.com/e_considine/status/1658844083438190594) by @e_considine which uses a clever thought experiment on killing people via the roll of a die a la No Country For Old Men.  Credit to many of the people who responded to my threads, and I learned a lot in communication.\n\nBut the question remains: why do people believe a large r squared is important for inference?  At this point I can only hypothesize, but let me do so anyway.  Perhaps what these people are doing is confusing uncertainty in the data with uncertainty in an estimate.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}