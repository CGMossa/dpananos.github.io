{
  "hash": "7cd1758a2b02806d920fd142e0021b3c",
  "result": {
    "markdown": "---\ntitle: Estimating the Shifted Beta Geometric Model in Stan\ndate: \"2023-11-20\"\ncode-fold: true\necho: true\nfig-cap-location: top\ncategories: []\nnumber-sections: false\ndraft: false\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cmdstanr)\n```\n:::\n\n\nThe shifted beta geometric model (sBG) is a model that is used to forecast retention/survival of users in contractual settings (think netflix, disney plus, tinder gold, etc). The model is quite simple and posits:\n\n* At the end of each period, a customer flips a coin: \"heads\" she cancels he contract, \"tails\" she renews it.\n* For each individual, the probability of a coin coming up \"heads\" does not change over time\n* The probabiliuty of heads varies across customers.  Fader and Hardie motivate the model in their paper *How to Project Customer Retention* and even provide a way to fit the model in excel. Neat!\n\nExcel isn't a great tool for fitting models, so Let's write this in Stan.\n\n## sBG in Stan\n\nThe two things we need are the probability density function and the survival function. Fader and Hardie provide these in their paper.  Mathematically, the probability density and survival function are\n\n$$ P(T=t \\mid \\alpha, \\beta) = \\dfrac{B(\\alpha+1, \\beta+t-1)}{B(\\alpha, \\beta)} \\>,$$\n\n$$ S(T=t \\mid \\alpha, \\beta) = \\dfrac{B(\\alpha, \\beta+t)}{B(\\alpha, \\beta)} \\>. $$\nHere, $B(\\alpha, \\beta)$ is the beta function *and not the beta distribution* (I made that mistake early).  Stan operates on the log scale, and so we'll have to take the log of these.  Stan has a log beta function called `lbeta` so we'll use that in our functions for the density and survival function.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.stan}\nfunctions{\n  real sbg_lpdf(real time, real alpha, real beta){\n    \n    return lbeta(alpha+1, beta+time-1) - lbeta(alpha, beta);\n  }\n  \n  real sbg_lccdf(real time, real alpha, real beta){\n    \n    return lbeta(alpha, beta + time) - lbeta(alpha, beta);\n  }\n  \n}\n```\n:::\n:::\n\n\nThe data we need to fit the model include:\n\n* How many customers were lost at each time period, \n* The times at which customers were lost, and\n* The total number of customers under observation\n\nWe'll also include an array of times at which to estimate the survival curve\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata{\n  // Fitting the model\n  int N;\n  int n_total;\n  array[N] int lost;\n  array[N] real time;\n  \n  // Making Predictions\n  int N_pred;\n  array[N_pred] real pred_times;\n}\n```\n:::\n:::\n\n\n\nLater, we'll need the last time point we observed customers who haven't churned.  This is the truncation time\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ntransformed data{\n  real truncation_time = max(time);\n}\n```\n:::\n:::\n\n\nAll that is left to do is specify parameters, write the model block, and generate predictions for our survival curve.  The likelihood computations are shown in the paper I referenced, so I'll let you read that if you're interested\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.stan}\nparameters{\n  real<lower=0> alpha;\n  real<lower=0> beta;\n}\nmodel{\n  alpha ~ cauchy(0, 1);\n  beta ~ cauchy(0, 1);\n  \n  for(i in 1:N){\n    target += lost[i] * sbg_lpdf(time[i]| alpha, beta);\n  }\n  target += (n_total - sum(lost)) * sbg_lccdf(truncation_time| alpha, beta);\n}\ngenerated quantities{\n  \n  array[N_pred] real expected_surviving;\n  \n  for(i in 1:N_pred){\n    expected_surviving[i] = exp(sbg_lccdf(pred_times[i]| alpha, beta));\n  }\n  \n}\n```\n:::\n:::\n\n# Fitting the Model\n\nFader and Hardie provide an example in their appendix for fitting the model.  We'll use that data to check our fit.  Let's take a look at that data now\n\n\n::: {.cell fig.asp='0.6'}\n\n```{.r .cell-code}\nlibrary(cmdstanr)\nlibrary(tidyverse)\nlibrary(tidybayes)\n\nstan_data <- list(\n  active = c(863 ,743 ,653 ,593 ,551 ,517 ,491),\n  lost = c(131, 126 ,90 ,60 ,42 ,34 ,26),\n  N = 7,\n  n_total = 1000,\n  time = 1:7,\n  N_pred = 25,\n  pred_times = seq(0, 12, length.out=25)\n)\n\n\nsurv_plot <- tibble(time = stan_data$time, active=stan_data$active) %>% \n              ggplot(aes(time, active)) + \n              geom_point() + \n              geom_line() + \n              ylim(c(0, 1000)) + \n              ylab('Customers Surviving') +\n              xlab('Time') + \n              see::theme_modern() + \n              theme(aspect.ratio = 1/1.61,\n                    panel.grid.major = element_line())\n\nsurv_plot\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=768}\n:::\n:::\n\n\nNow, let's compare with the fit\n\n\n::: {.cell fig.asp='0.6'}\n\n```{.r .cell-code}\nmodel <- cmdstanr::cmdstan_model('sbg.stan')\n\nfit <- model$sample(stan_data, refresh = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n```\n:::\n\n```{.r .cell-code}\npred_times <- tibble(pred_times=stan_data$pred_times, i = seq_along(pred_times))\nfit_predict <- fit %>% \n               spread_draws(expected_surviving[i]) %>% \n               mutate(expected_surviving = expected_surviving * 1000) %>% \n               mean_qi() %>% \n               left_join(pred_times)\n\n\n\nsurv_plot + \n  geom_line(data=fit_predict, aes(pred_times, expected_surviving), inherit.aes = F, color='red') + \n  geom_ribbon(data=fit_predict, aes(pred_times, ymin = .lower, ymax=.upper), inherit.aes = F, fill='red', alpha=0.5)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=768}\n:::\n:::\n\n\nNice, not a bad fit.\n\nModel extensions seem fairly straight forward.  You could maybe model alpha and beta much in the same way you do for a beta regression.\n\n# Regression\n\nIn that same paper are two examples of survival curves; one for \"high end\" customers and another for \"regular\" customers.  It should be fairly straight forward to write this as a regression model. If you've written a beta regression before, you can do this fairly readily.\n\nNow, be warned:  My approach is pretty hacky, but its just meant to illustrate a point.  Here is the regression model in full\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.stan}\nfunctions{\n  real sbg_lpdf(real time, real alpha, real beta){\n    \n    return lbeta(alpha+1, beta+time-1) - lbeta(alpha, beta);\n  }\n  \n  real sbg_lccdf(real time, real alpha, real beta){\n    \n    return lbeta(alpha, beta + time) - lbeta(alpha, beta);\n  }\n  \n}\ndata{\n  // Observations\n  int n;\n  // Predictors (2 in this case)\n  int p;\n  array[n] real time;\n  // Design matrix\n  matrix[n, p] X;\n  array[n] int lost;\n  // These are the hacky bits.  I just don't want to work hard to \n  // Compute these in stan, so I do them in R.\n  array[n] int sum_lost;\n  array[n] int n_total;\n}\ntransformed data{\n  real truncation_time = max(time);\n}\nparameters{\n  vector[p] zeta;\n  vector[p] gamma;\n}\ntransformed parameters{\n  vector<lower=0, upper=1>[n] mu = inv_logit(X * zeta);\n  vector<lower=0>[n] kappa = exp(X * gamma);\n  \n  // Kind of like beta regression.\n  vector[n] alpha = mu./kappa;\n  vector[n] beta = (1-mu)./kappa;\n}\nmodel{\n  zeta ~ student_t(3.5, 0, 1);\n  gamma ~ student_t(3.5, 0, 1);\n  \n  for(i in 1:n){\n    if (time[i] == truncation_time){\n      target += lost[i] * sbg_lpdf(time[i]| alpha[i], beta[i]);\n      target += (n_total[i] - sum_lost[i]) * sbg_lccdf(truncation_time| alpha[i], beta[i]);\n    }\n    else{\n      target += lost[i] * sbg_lpdf(time[i]| alpha[i], beta[i]);\n    }\n  }\n}\ngenerated quantities{\n   array[n] real expected_surviving;\n  \n  for(i in 1:n){\n    expected_surviving[i] = exp(sbg_lccdf(time[i]| alpha[i], beta[i]));\n  }\n}\n```\n:::\n:::\n\n::: {.cell fig.asp='0.6'}\n\n```{.r .cell-code}\n# Sorry for the spaghetti\n\nregular_surv <- c( 631, 468, 382, 326, 289, 262, 241, 223, 207, 194, 183, 173)\nhighend_surv <- c( 869, 743, 653, 593, 551, 517, 491, 468, 445, 427, 409, 394)\n\nd <- tibble(\n  Regular = regular_surv,\n  `High End` = highend_surv,\n  time = 1:length(regular_surv)\n) %>% \n  pivot_longer(Regular:`High End`, \n               names_to = 'customer', \n               values_to = 'surviving') %>% \n  group_by(customer) %>% \n  arrange(customer) %>% \n  mutate(high_end = as.numeric(customer=='High End'),\n         lost = if_else(time ==1, 1000-surviving, lag(surviving, 1) - surviving),\n         n_total=1000,\n         sum_lost = sum(lost)) %>% \n  ungroup %>% \n  mutate(i = seq_along(time))\n  \nX <- model.matrix(~high_end, data=d)\n\nstan_data <- list(\n  n=nrow(X),\n  p=ncol(X),\n  X=X,\n  n_total=d$n_total,\n  lost=d$lost,\n  time=d$time,\n  sum_lost = d$sum_lost\n)\n\nmodel <- cmdstanr::cmdstan_model('sbg_regression.stan')\n\nchains <- parallel::detectCores()\nfit <- model$sample(stan_data, parallel_chains = chains, refresh = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 chains, at most 10 in parallel...\n\nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.2 seconds.\nChain 3 finished in 0.2 seconds.\nChain 4 finished in 0.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.3 seconds.\n```\n:::\n\n```{.r .cell-code}\nfit %>% \n  spread_draws(expected_surviving[i]) %>% \n  mean_qi %>% \n  left_join(d) %>% \n  ggplot() + \n  geom_point(aes(time, surviving, color=customer)) + \n  geom_line(aes(time, 1000*expected_surviving, color=customer)) + \n  geom_ribbon(aes(time, 1000*expected_surviving, ymin = 1000*.lower, ymax = 1000*.upper, fill=customer), alpha = 0.25) + \n  see::theme_modern() + \n  ylim(c(0, 1000)) + \n  ylab('Customers Surviving') +\n  xlab('Time') + \n  see::theme_modern() + \n  theme(aspect.ratio = 1/1.61,\n        panel.grid.major = element_line()) + \n  scale_color_brewer(palette = 'Set1') + \n  scale_fill_brewer(palette = 'Set1')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=768}\n:::\n:::\n\n\n\n\n# References\n\nFader, Peter S., and Bruce GS Hardie. \"How to project customer retention.\" Journal of Interactive Marketing 21.1 (2007): 76-90.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}