{
  "hash": "216fd7edb8b24b08f41e1ac5a05ad82f",
  "result": {
    "markdown": "---\ntitle: The Generalized Gamma Distribution For Parametric Survival\ndate: \"2023-12-02\"\ncode-fold: true\necho: true\nfig-cap-location: top\ncategories: []\nnumber-sections: false\ndraft: false\n---\n\n\nA couple weeks back, I posted a little something something on [the Shifted Beta Geometric distribution](https://dpananos.github.io/posts/2023-11-02-shifted-beta-geometric/).  That distribution is used in estimating churn in contractual settings (think Netflix, or any other service whereby you renew your service monthly).  Its a nice model, but I want something more flexible.  \n\nI've been aware of the generalized gamma  distribution through Jordan Nafa (who likely uses it for some very interesting decision theory applications). Briefly, if $T$ is the event time, then let $Y=\\log(T)$, and $Z = (Y-\\mu)/\\sigma$.  Then $Z$ has the following density\n\n$$ f(z ; k)=\\frac{k^{k-1 / 2}}{\\Gamma(k)} \\exp \\left(k^{1 / 2} z-k e^{k^{-1 / 2} z}\\right)$$\n\nand $T = \\exp(Y)$ is distributed according to the generalized gamma distribution .  Here, $-\\infty \\lt z \\lt \\infty$, $-\\infty \\lt \\mu \\lt \\infty$,  and $\\sigma, k>0$.  For more on the generalized gamma, especially for use in survival analysis, see *Statistical Models and Methods for Lifetime Data* by Jerry Lawless (1982).\n\nThe nice thing about the generalized gamma is that the exponential,  gamma, and  weibull distributions -- all common parmetric survival likelihoods -- are special cases (and the log normal is a limiting distribution) [^1].  \nThat is especially nice for me.  I'm working on some life time value modelling and it would be great if I didn't have to try several models.  Instead I can just use the generalized gamma and hope it fits well enough if the data are best approximated via one of the aforementioned survival functions.\n\nIn this post, I want to implement some survival analyses using the generalized gamma. \nLet's get started.\n\n## Data\n\nWe'll need some data. Rather than simulate it myself, I'll use the `veteran` data from `{survival}`.  The survival function is roughly exponential, which is good because we know the generalized gamma can fit it in principle.  There is a `trt` indicator in these data, so we'll fit one survival curve to each strata.  Shown below are the Kaplan-Meir non-parametric estimates for these data.  Rather than plot the survival curve $S(t)$, I choose to plot $1-S(t)$ because my brain groks the plot easier as \"the proportion of individuals in a cohort who would have experienced the outcome by time $t$\".  The log of this quantity is the cumulative hazard, but I don't know if $1-S(t)$ has a proper name.  I mean ... it is technically an estimate of the CDF of the event time distribution.  \n\n\n::: {.cell}\n::: {.cell-output-display}\n![Non-parametric estimate of $1 - S(t|trt)$ for each `trt` strata in the veteran dataset.  The curves look roughly exponential meaning the generalized gamma should provide a good fit.](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nStan does not have an implementation for the generalized gamma, so we'll have to write that ourselves in the `functions` block.\n\n## `_lpdf`, `_lcdf`, and `_lccdf` Implementations in Stan\n\nTo do parametric survival analysis in Stan, we need three functions:\n\n* The log probability density as `generalized_gamma_lpdf` so we can increment the log posterior density when we observe an outcome,\n* The log complementary CDF as `generalized_gamma_lccdf` so we can increment the log posterior density when we observe a censoring event, and \n* The log CDF as `generalized_gamma_lcdf` so we can implement the `_lccdf`.\n\n\nThe first and third functions are implemented already by Krzysztof Sakrejda in [this repo](https://github.com/sakrejda/tooling/blob/master/models/stan-lang/functions/generalized-gamma.stan.part).  The `_lpdf` and `_lcdf` are given, so now we just need the complementary cdf function `_lccdf`. Since Stan works on the log probability scale, we need to return the the log of the complementary cdf.  Since we have the log cdf we could just do\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.stan}\n\n\nreal generalized_gamma_lccdf(real x, real k, real mu, real sigma) {\n \n return log(1 - exp(generalized_gamma_lcdf(x | k, mu sigma)));\n \n}\n```\n:::\n:::\n\n\n\nStan has a nicer function to do this called `log_diff_exp` which can be used to take differences in exponential space and then take the log of the result.  \n\n\nAdditionally, we can create a random number generator for the generalized gamma distribution by noting that `flexsurv`'s implementation of the generalized gamma is equivalent to ours if we let $Q=1/\\sqrt{k}$.  Our `functions` block then looks like\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.stan}\nfunctions {\n  \n  real generalized_gamma_lpdf(real x, real k, real mu, real sigma) {\n    real w;\n    real d;\n    w = (log(x) - mu) / sigma;\n    d = (k - .5) * log(k) - log(sigma) - lgamma(k) + (sqrt(k) * w - k * exp(1 / sqrt(k) * w)) - log(x);\n    \n    return d;\n  }\n  \n  real generalized_gamma_cdf(real x, real k, real mu, real sigma) {\n    real w;\n    real d;\n    w = (log(x) - mu) / sigma;\n    d = gamma_p(k, k * exp(w / sqrt(k)));\n    \n    return d;\n  }\n  \n  real generalized_gamma_lcdf(real x, real k, real mu, real sigma) {\n    real w;\n    real d;\n    w = (log(x) - mu) / sigma;\n    d = log(gamma_p(k, k * exp(1 / sqrt(k) * w)));\n    return d;\n  }\n  \n  real generalized_gamma_lccdf(real x, real k, real mu, real sigma) {\n    return log_diff_exp(0, generalized_gamma_lcdf(x | k, mu, sigma));\n  }\n  \n  real generalized_gamma_rng(real k, real mu, real sigma) {\n    real Q = 1.0 / sqrt(k);\n    real gamma = gamma_rng(Q^-2, 1);\n    real w = log(Q^2 * gamma) / Q;\n    return exp(mu + sigma * w);\n  }\n  \n```\n:::\n:::\n\n\n\n## Fitting The Model\n\nThe model fits fairly quickly (4 chains in parallel takes <2 seconds on my M1 Pro macbook pro).  We can easily plot the survival curve against the Kaplan-Meir estimate to compare, however a better comparison would be to draw samples from the event time distribution and compute the ecdf of those samples. That plot is shown below, and is equivalent to a posterior predictive check in the case where there is no censoring.  You can see that the KM estimates look similar to the ecdfs, which is good enough for me.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 chains, at most 10 in parallel...\n\nChain 1 finished in 1.9 seconds.\nChain 2 finished in 1.9 seconds.\nChain 3 finished in 1.9 seconds.\nChain 4 finished in 1.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.9 seconds.\nTotal execution time: 2.0 seconds.\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Kaplan-Meir estimates (black) with posterior survival functions.](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Kaplan-Meir estimates (black) with estimated ECDFs computed from draws of the posterior distribution.  Each colored line corresponds to one sample of event times from the posterior distribution, conditional on $\\mu$, $\\sigma$, and $k$.](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n[^1]: Left as an exercise to the reader.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}